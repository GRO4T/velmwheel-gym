[trainer]
log_level = trace
gym_env = Velmwheel2D250-v0
algorithm = TD3
model = 
replay_buffer =
; model = models/td3/200/td3_3860000_steps.zip
; replay_buffer = models/td3/200/td3_replay_buffer_3750000_steps.pkl
timesteps = 120000
save_freq = 20000
replay_buffer_save_freq = 100000
navigation_difficulty_level = 0
real_time_factor = 1.0
envs = 1
monitor_network = false
render = false

[tester]
log_level = debug
gym_env = Velmwheel2D250-v0
algorithm = TD3
; model = models/td3/101/td3_2840000_steps.zip
; model = models/td3/123/td3_660000_steps.zip
; model = models/td3/133/td3_20000_steps.zip
model = models/td3/202/td3_120000_steps.zip
;model = models/td3/133/td3_1080000_steps.zip
replay_buffer = 
navigation_difficulty_level = 0
real_time_factor = 1.0
goal_x = 7.0
goal_y = 7.0
start_x = -7.0
start_y = -7.0
render = true

[VelmwheelGym]
global_path_segment_length = 2.5
render_freq = 1
; variant = NoGlobalGuidance
variant = EasierFollowing
; variant = HarderFollowing

[PPO]
gamma = 0.96
learning_rate = 0.001
n_steps = 512
batch_size = 256

[DDPG]
learning_starts = 50000
gamma = 0.99
batch_size = 1024
buffer_size = 250000
actor_lr = 0.001
critic_lr = 0.001

[TD3]
learning_starts = 100
gamma = 0.99
batch_size = 256
buffer_size = 1000000
actor_lr = 0.001
critic_lr = 0.001
noise_decay_steps = 1000000

