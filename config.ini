[trainer]
# info, debug, trace
log_level = trace
gym_env = Velmwheel2D500-v0
algorithm = PPO
; model =
replay_buffer =
model = ./models/velmwheel_v1/ppo/6/ppo_260000_steps.zip
; replay_buffer = ./models/velmwheel_v1/td3/12/td3_replay_buffer_700000_steps.pkl
timesteps = 3000000
goal_reached_threshold = 1.0
real_time_factor = 8.0
envs = 1 

[tester]
# info, debug, trace
log_level = debug
gym_env = Velmwheel2D500-v0
algorithm = PPO
model = ./models/velmwheel_v1/ppo/5/ppo_60000_steps.zip
replay_buffer = ./models/velmwheel_v1/td3/14/td3_replay_buffer_340000_steps.pkl
goal_reached_threshold = 1.0
real_time_factor = 1.0
goal_x = -3.0
goal_y = -3.0

[PPO]
learning_rate = 0.0003

[DDPG]
gamma = 0.9999
buffer_size = 50000

[TD3]
batch_size = 100
